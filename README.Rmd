---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  fig.path = "man/figures/"
)
```

# insurancerating <img src="logo.png" align="right" alt="" width="120" />

<!-- badges: start -->
[![CRAN Status](https://www.r-pkg.org/badges/version/insurancerating)](https://cran.r-project.org/package=insurancerating)
[![Downloads](https://cranlogs.r-pkg.org/badges/insurancerating?color=blue)](https://cran.rstudio.com/package=insurancerating)
<!-- badges: end -->

The goal of `insurancerating` is to give analytic techniques that can be used in insurance rating. It helps actuaries to implement GLMs within all relevent steps needed to construct a risk premium from raw data. It provides a data driven strategy for the construction of tariff classes in P&C insurance. The goal is to bin the continuous factors such that categorical risk factors result which capture the effect of the covariate on the response in an accurate way, while being easy to use in a generalized linear model (GLM).

`insurancerating` also provides recipes on how to easily perform univariate analyses on an insurance portfolio. In addition it adds functionality to include reference categories in the levels of the coefficients in the output of a generalized linear regression analysis. 

## Installation

Install insurancerating from CRAN:

```{r, eval = FALSE}
install.packages("insurancerating")
```

Or the development version from GitHub:

```{r gh-installation, eval = FALSE}
# install.packages("remotes")
remotes::install_github("MHaringa/insurancerating")

```

## Example 1
This is a basic example which shows the techniques provided in insurancerating. 

The first part shows how to fit a GAM for the variable *age_policyholder* in the MTPL dataset: 

```{r example, eval = TRUE, message = FALSE, warning = FALSE}
library(insurancerating)

# Claim frequency 
age_policyholder_frequency <- fit_gam(data = MTPL, 
                                      nclaims = nclaims, 
                                      x = age_policyholder, 
                                      exposure = exposure)

# Claim severity 
age_policyholder_severity <- fit_gam(data = MTPL, 
                                     nclaims = nclaims, 
                                     x = age_policyholder, 
                                     exposure = exposure, 
                                     amount = amount, 
                                     model = "severity")
```

Create plot:

```{r plotgam, eval = TRUE}

autoplot(age_policyholder_frequency, show_observations = TRUE)

```

Determine classes for the claim frequency (the points show the ratio between the observed number of claims and exposure for each age): 

```{r figfreq, eval = TRUE}

clusters_freq <- construct_tariff_classes(age_policyholder_frequency)
clusters_sev <- construct_tariff_classes(age_policyholder_severity)

autoplot(clusters_freq, show_observations = TRUE)
```

The figure shows that younger policyholders have a higher risk profile. The fitted GAM is lower than might be expected from the observed claim frequency for policyholders of age 19. This is because there are very few young policyholders of age 19 present in the portfolio. 

The GAM for the claim severity : 

```{r figsev, eval = TRUE}

age_policyholder_severity %>%
  autoplot(., show_observations = TRUE, remove_outliers = 100000)

```

The second part adds the constructed tariff classes for the variable `age_policyholder` to the dataset, and sets the base level of the factor `age_policyholder` to the level with the largest exposure. In this example for claim frequency the class for ages (39,50], which contains the largest exposure. 

```{r example2, eval = TRUE, message = FALSE, warning = FALSE}

library(dplyr)

dat <- MTPL %>%
  mutate(age_policyholder_freq_cat = clusters_freq$tariff_classes) %>%
  mutate_if(is.character, as.factor) %>%
  mutate_if(is.factor, list(~biggest_reference(., exposure)))

glimpse(dat)

```

The last part is to fit a *generalized linear model*. `rating_factors()` prints the output including the reference group.

```{r example3, eval = TRUE}

model_freq1 <- glm(nclaims ~ age_policyholder_freq_cat, offset = log(exposure), 
                  family = "poisson", data = dat)

model_freq2 <- glm(nclaims ~ age_policyholder_freq_cat + age_policyholder, offset = log(exposure), 
                  family = "poisson", data = dat)

x <- rating_factors(model_freq1, model_freq2) 
x

```

`autoplot.riskfactor()` creates a figure. The base level of the factor `age_policyholder_freq_cat` is the group with the largest exposure and is shown first. 

```{r example3a1, eval = TRUE}

autoplot(x)

```

Include `model_data` to sort the clustering in the original order. Ordering the factor `age_policyholder_freq_cat` only works when `biggest_reference()` is used to set the base level of the factor to the level with the largest exposure. 

```{r example3b, eval = TRUE}

rating_factors(model_freq1, model_freq2, model_data = dat) %>%
  autoplot()

```

The following graph includes the exposure as a bar graph and shows some more options: 

```{r example3c, eval = TRUE}

rating_factors(model_freq1, model_freq2, model_data = dat, exposure = exposure) %>%
  autoplot(., linetype = TRUE, color_bg = "skyblue") 

```

Check Poisson GLM for overdispersion:

```{r overdispersion, eval = TRUE}
check_overdispersion(model_freq1)
```

Check model for (non-)normality of residuals. Normality of deviance residuals is in general not expected under a Poisson, and seing deviance residuals (or any other standard residuals) that differ from a straight line in a qqnorm plot is therefore in general no concern at all. 

```{r normality, message = FALSE, eval = TRUE}
check_normality(model_freq1, simulate_residuals = FALSE) %>%
  autoplot(.)
```

Instead, setting `simulate_residuals = TRUE` corrects for notable deviations from normality for small counts. It implements the idea of randomized quantile residuals by Dunn and Smyth (1996). `check_normality()` adopts the implementation of this approach from `simulateResiduals()` in package DHARMa. Note that (for large data sets) formal tests for normality almost always yields significant results for the distribution of residuals and visual inspections (e.g. QQ plots) are preferable. The simulated residuals in the QQ plot show no clear deviation from normality.

```{r normalitysim, message = FALSE, eval = TRUE}
check_normality(model_freq1, simulate_residuals = TRUE, n_simulations = 50) %>%
  autoplot(.)
```


## Example 2
This is a basic example which shows how to easily perform an univariate analysis on a MTPL portfolio using `insurancerating`.

An univariate analysis consists in the evaluation of overall claim frequency, severity and risk premium. Its main purpose lies in verifying the experience data reasonableness using previous experience comparison and professional judgement.

`univariate()` shows the basic risk indicators split by the levels of the discrete risk factor:

```{r example4}

library(insurancerating)
univariate(MTPL2, 
           x = area, # discrete risk factor
           nclaims = nclaims, # number of claims
           exposure = exposure, 
           premium = premium, 
           severity = amount) # loss

```

The following indicators are calculated:

1. frequency (i.e. frequency = number of claims / expsore)
2. average_severity (i.e. average severity = severity / number of claims)
3. risk_premium (i.e. risk premium = severity / exposure = frequency x average severity)
4. loss_ratio (i.e. loss ratio = severity / premium)
5. average_premium (i.e. average premium = premium / exposure)

The term risk premium is used here as an equivalent of pure premium and burning cost.

`univariate()` ignores missing input arguments, for instance only the claim frequency is calculated when `premium` and `severity` are unknown:

```{r example 5}

univariate(MTPL2, x = area, nclaims = nclaims, exposure = exposure) 

```

However, the above table is small and easy to understand, the same information might be presented more effectively with a graph, as shown below.

```{r example6, eval = TRUE, message = FALSE}

univariate(MTPL2, x = area, nclaims = nclaims, exposure = exposure) %>%
  autoplot(.)

```

In `autoplot.univariate()`, `show_plots` defines the plots to show and also the order of the plots. The following plots are available: 

1. frequency 
2. average_severity 
3. risk_premium 
4. loss_ratio 
5. average_premium 
6. exposure
7. severity
8. nclaims
9. premium

For example, to show the exposure and claim frequency plots:

```{r example7}

univariate(MTPL2, x = area, nclaims = nclaims, exposure = exposure) %>%
  autoplot(., show_plots = c(6,1))

```

To remove the bars from the plot with the line graph, add `background = FALSE`: 

```{r example8}

univariate(MTPL2, x = area, nclaims = nclaims, exposure = exposure) %>%
  autoplot(., show_plots = c(6,1), background = FALSE)

```

`sort` orders the levels of the risk factor into descending order by exposure:

```{r example9}

univariate(MTPL2, x = area, nclaims = nclaims, exposure = exposure) %>%
  autoplot(., show_plots = c(6,1), background = FALSE, sort = TRUE)

```

`sort_manual` in `autoplot.univariate()` can be used to sort the levels of the discrete risk factor into your own ordering. This makes sense when the levels of the risk factor has a natural order, or when not all levels of the risk factor are desired in the output.  

```{r example10, eval = TRUE}

univariate(MTPL2, x = area, nclaims = nclaims, exposure = exposure) %>%
  autoplot(., show_plots = c(6,1), background = FALSE, sort_manual = c("2", "3", "1", "0"))

```

The following graph shows some more options: 

```{r example11, fig.width = 10, fig.height = 5}

univariate(MTPL2, x = area, nclaims = nclaims, exposure = exposure) %>%
  autoplot(., show_plots = c(6,1), background = FALSE, sort = TRUE, ncol = 2, 
           color_bg = "dodgerblue", color = "blue")

```

Or create a bar graph for the number of claims:

```{r example12, eval = TRUE, message = FALSE, warning = FALSE}

univariate(MTPL2, x = area, nclaims = nclaims) %>%
  autoplot(., coord_flip = TRUE, sort = TRUE)

```








